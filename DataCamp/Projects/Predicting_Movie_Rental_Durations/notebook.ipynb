{"cells":[{"source":"![dvd_image](dvd_image.jpg)\n\nA DVD rental company needs your help! They want to figure out how many days a customer will rent a DVD for based on some features and has approached you for help. They want you to try out some regression models which will help predict the number of days a customer will rent a DVD for. The company wants a model which yeilds a MSE of 3 or less on a test set. The model you make will help the company become more efficient inventory planning.\n\nThe data they provided is in the csv file `rental_info.csv`. It has the following features:\n- `\"rental_date\"`: The date (and time) the customer rents the DVD.\n- `\"return_date\"`: The date (and time) the customer returns the DVD.\n- `\"amount\"`: The amount paid by the customer for renting the DVD.\n- `\"amount_2\"`: The square of `\"amount\"`.\n- `\"rental_rate\"`: The rate at which the DVD is rented for.\n- `\"rental_rate_2\"`: The square of `\"rental_rate\"`.\n- `\"release_year\"`: The year the movie being rented was released.\n- `\"length\"`: Lenght of the movie being rented, in minuites.\n- `\"length_2\"`: The square of `\"length\"`.\n- `\"replacement_cost\"`: The amount it will cost the company to replace the DVD.\n- `\"special_features\"`: Any special features, for example trailers/deleted scenes that the DVD also has.\n- `\"NC-17\"`, `\"PG\"`, `\"PG-13\"`, `\"R\"`: These columns are dummy variables of the rating of the movie. It takes the value 1 if the move is rated as the column name and 0 otherwise. For your convinience, the reference dummy has already been dropped.","metadata":{},"id":"b4ae5707-109f-4cd6-8168-88cac0179d6b","cell_type":"markdown"},{"source":"### Libraries ###\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBRegressor\n\n### Load an clean data ##\ndf = pd.read_csv('rental_info.csv')\ndf['rental_date'] = pd.to_datetime(df['rental_date'])\ndf['return_date'] = pd.to_datetime(df['return_date'])\ndf['rental_length_days'] = (df['return_date'] - df['rental_date']).dt.days\ndf['deleted_scenes'] = df['special_features'].apply(lambda x: 1 if 'Deleted Scenes' in x else 0)\ndf['behind_the_scenes'] = df['special_features'].apply(lambda x: 1 if 'Behind the Scenes' in x else 0)\n#years = pd.get_dummies(df['release_year'], prefix='released')\n#df = pd.concat([df, years], axis=1)\n#X = df.drop(['release_year', 'rental_length_days', 'rental_date', 'return_date', 'special_features', 'length_2', 'amount_2', 'rental_rate_2'], axis=1)\nX = df.drop(['rental_length_days', 'rental_date', 'return_date', 'special_features'], axis=1)\n#, 'length_2', 'amount_2', 'rental_rate_2'\ny = df['rental_length_days']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n\n### Standardize features ###\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n### Lasso Regression ###\nlasso = Lasso(random_state=9)\nlasso_params = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\nlasso_grid = GridSearchCV(lasso, lasso_params, cv=5, scoring='neg_mean_squared_error')\nlasso_grid.fit(X_train_scaled, y_train)\nbest_lasso = lasso_grid.best_estimator_\nlasso_pred = best_lasso.predict(X_test_scaled)\nlasso_mse = mean_squared_error(y_test, lasso_pred)\n\n### XGBoost Regression ###\nxgb = XGBRegressor(random_state=9, objective='reg:squarederror')\nxgb_params = {\n    'n_estimators': [50, 100],\n    'max_depth': [3, 5],\n    'learning_rate': [0.01, 0.1, 0.2]\n}\nxgb_grid = GridSearchCV(xgb, xgb_params, cv=5, scoring='neg_mean_squared_error')\nxgb_grid.fit(X_train, y_train)\nbest_xgb = xgb_grid.best_estimator_\nxgb_pred = best_xgb.predict(X_test)\nxgb_mse = mean_squared_error(y_test, xgb_pred)\n\n### Best Model ###\nprint(f\"Lasso Regression MSE: {lasso_mse:.4f} (Best alpha: {best_lasso.alpha})\")\nprint(f\"XGBoost MSE: {xgb_mse:.4f} (Best params: {xgb_grid.best_params_})\")\n\nif xgb_mse < lasso_mse:\n    best_model = best_xgb\n    best_mse = xgb_mse\n    print(\"\\n XGBoost\")\nelse:\n    best_model = best_lasso\n    best_mse = lasso_mse\n    print(\"\\n Lasso\")","metadata":{"executionCancelledAt":null,"executionTime":30233,"lastExecutedAt":1745139572586,"lastExecutedByKernel":"e9f91962-b278-4eae-8f37-09e83563d4be","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"### Libraries ###\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBRegressor\n\n### Load an clean data ##\ndf = pd.read_csv('rental_info.csv')\ndf['rental_date'] = pd.to_datetime(df['rental_date'])\ndf['return_date'] = pd.to_datetime(df['return_date'])\ndf['rental_length_days'] = (df['return_date'] - df['rental_date']).dt.days\ndf['deleted_scenes'] = df['special_features'].apply(lambda x: 1 if 'Deleted Scenes' in x else 0)\ndf['behind_the_scenes'] = df['special_features'].apply(lambda x: 1 if 'Behind the Scenes' in x else 0)\n#years = pd.get_dummies(df['release_year'], prefix='released')\n#df = pd.concat([df, years], axis=1)\n#X = df.drop(['release_year', 'rental_length_days', 'rental_date', 'return_date', 'special_features', 'length_2', 'amount_2', 'rental_rate_2'], axis=1)\nX = df.drop(['rental_length_days', 'rental_date', 'return_date', 'special_features'], axis=1)\n#, 'length_2', 'amount_2', 'rental_rate_2'\ny = df['rental_length_days']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n\n### Standardize features ###\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n### Lasso Regression ###\nlasso = Lasso(random_state=9)\nlasso_params = {'alpha': [0.001, 0.01, 0.1, 1, 10]}\nlasso_grid = GridSearchCV(lasso, lasso_params, cv=5, scoring='neg_mean_squared_error')\nlasso_grid.fit(X_train_scaled, y_train)\nbest_lasso = lasso_grid.best_estimator_\nlasso_pred = best_lasso.predict(X_test_scaled)\nlasso_mse = mean_squared_error(y_test, lasso_pred)\n\n### XGBoost Regression ###\nxgb = XGBRegressor(random_state=9, objective='reg:squarederror')\nxgb_params = {\n    'n_estimators': [50, 100],\n    'max_depth': [3, 5],\n    'learning_rate': [0.01, 0.1, 0.2]\n}\nxgb_grid = GridSearchCV(xgb, xgb_params, cv=5, scoring='neg_mean_squared_error')\nxgb_grid.fit(X_train, y_train)\nbest_xgb = xgb_grid.best_estimator_\nxgb_pred = best_xgb.predict(X_test)\nxgb_mse = mean_squared_error(y_test, xgb_pred)\n\n### Best Model ###\nprint(f\"Lasso Regression MSE: {lasso_mse:.4f} (Best alpha: {best_lasso.alpha})\")\nprint(f\"XGBoost MSE: {xgb_mse:.4f} (Best params: {xgb_grid.best_params_})\")\n\nif xgb_mse < lasso_mse:\n    best_model = best_xgb\n    best_mse = xgb_mse\n    print(\"\\n XGBoost\")\nelse:\n    best_model = best_lasso\n    best_mse = lasso_mse\n    print(\"\\n Lasso\")"},"cell_type":"code","id":"d27359f9-dc25-4d1f-98a5-5d7ff4c1bc2d","outputs":[{"output_type":"stream","name":"stdout","text":"Lasso Regression MSE: 2.9417 (Best alpha: 0.001)\nXGBoost MSE: 2.0651 (Best params: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100})\n\n XGBoost\n"}],"execution_count":96}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}